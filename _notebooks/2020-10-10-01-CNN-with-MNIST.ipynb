{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with MNIST dataset\n",
    "> In this post, we will implement various type of CNN for MNIST dataset. In Tensorflow, there are various ways to define CNN model like sequential model, functional model, and sub-class model. We'll simply implement each type and test it.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Deep_Learning, Tensorflow-Keras]\n",
    "- image: images/CNN_MNIST.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rc('font', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model with sequential API\n",
    "Previously, we learned basic operation of convolution and max-pooling. Actually, we already implemented simple type of CNN model for MNIST classification, which is manually combined with 2D convolution layer and max-pooling layer. But there are other ways to define CNN model. In this section, we will implement CNN model with Sequential API.\n",
    "\n",
    "Briefly speaking, we will build the model as follows,\n",
    "\n",
    "![CNN](image/CNN_MNIST.png)\n",
    "\n",
    " 3x3 2D convolution layer is defined as an input layer, and post-process with 2x2 max-pooling. And these process will be redundant 3 times, then set fully-connected layer as an output layer for classification. In convolution layer, stride will be 1, and padding will be `same` (that is, we will use half padding). And in max-pooling layer, stride will be 2, and padding will also be `same`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter setting\n",
    "Firstly, we need to define hyperparameter that affect model training. For the review, **hyperparameter** is a parameter whose value is used to control the learning process, such as learning rate, epochs, and batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the tracking model training, it is helpful to build checkpoint while training the model, so when we the model training is failed due to unexpected reason, we can re-train it with checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "checkpoint_dir = os.path.join(cur_dir, 'checkpoints', 'mnist_cnn_seq')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'mnist_cnn_seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipelining\n",
    "Before model implementation, it requires data pipelining, also known as data-preprocess. As you can see from previous example, the original raw data is hardly used directly. So we need to normalize it, convert it, that we can express whole process as an \"data-preprocessing\".\n",
    "\n",
    "Note that, the label of each data is class label. So to use it in Neural network model, it needs to encode it as an binary code. Maybe someone already knew it, it is **one-hot** encoding. Luckily, tf.keras also implements `to_categorical` for one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalization\n",
    "X_train = X_train.astype(np.float32) / 255.\n",
    "X_test = X_test.astype(np.float32) / 255.\n",
    "\n",
    "# Convert it to 4D array (or we can use np.expand_dims for dimension expansion)\n",
    "X_train = X_train[..., tf.newaxis]\n",
    "X_test = X_test[..., tf.newaxis]\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build dataset pipeline\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=100000).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with Sequential API\n",
    "Building model with Sequential API is similar with previous example. The difference is that Sequential API pre-build the model skeleton, then add each specific layers. In this code, we will build one API to build whole models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential(name='CNN_Sequential')\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=tf.keras.activations.relu,\n",
    "                                     padding='SAME', input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.keras.activations.relu,\n",
    "                                     padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=tf.keras.activations.relu,\n",
    "                                     padding='SAME'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.keras.activations.relu))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, when we directly add the layer, we need to enter the input data for generating output. But in Sequential model, each previous layers node is connected with next layers node automatically, All we need to do is to input the data in the model, then output will be generated from the whole model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Gradient \n",
    "Same as MLP, we need to define loss function and use gradient descent for finding minimum loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(model, images, labels):\n",
    "    logits = model(images, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    return loss\n",
    "\n",
    "# Gradient Function\n",
    "def grad(model, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, images, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Evaluation\n",
    "For finding optimum value, we will use \"Adam\" Optimizer with predifined learning_rate. Also, we need to define evaluation function so that we can check the performance (or accuracy of model).\n",
    "\n",
    "One more thing, We already mention that checkpoint is required for tracking history. So we will define it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, images, labels):\n",
    "    logits = model(images, training=False)\n",
    "    correct_predict = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = tf.train.Checkpoint(cnn=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation\n",
    "Finally, we can train model with our training dataset. And also we need to check the performance while training the model, so after train the model in each epoch, we will also evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.18465614 train acc: 0.9539 test acc: 0.9866\n",
      "Epoch: 2 loss: 0.04830704 train acc: 0.9901 test acc: 0.9898\n",
      "Epoch: 3 loss: 0.03166568 train acc: 0.9929 test acc: 0.9918\n",
      "Epoch: 4 loss: 0.02311547 train acc: 0.9953 test acc: 0.9916\n",
      "Epoch: 5 loss: 0.01861383 train acc: 0.9964 test acc: 0.9931\n",
      "Epoch: 6 loss: 0.01619163 train acc: 0.9972 test acc: 0.9935\n",
      "Epoch: 7 loss: 0.01229716 train acc: 0.9979 test acc: 0.9908\n",
      "Epoch: 8 loss: 0.01014238 train acc: 0.9984 test acc: 0.9930\n",
      "Epoch: 9 loss: 0.00907810 train acc: 0.9986 test acc: 0.9932\n",
      "Epoch: 10 loss: 0.00838505 train acc: 0.9989 test acc: 0.9935\n",
      "Epoch: 11 loss: 0.00753370 train acc: 0.9991 test acc: 0.9941\n",
      "Epoch: 12 loss: 0.00646839 train acc: 0.9992 test acc: 0.9937\n",
      "Epoch: 13 loss: 0.00608160 train acc: 0.9995 test acc: 0.9916\n",
      "Epoch: 14 loss: 0.00588523 train acc: 0.9994 test acc: 0.9924\n",
      "Epoch: 15 loss: 0.00493233 train acc: 0.9995 test acc: 0.9924\n"
     ]
    }
   ],
   "source": [
    "for e in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        grads = grad(model, images, labels)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        loss = loss_fn(model, images, labels)\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_loss = avg_loss + loss\n",
    "        avg_train_acc = avg_train_acc + acc\n",
    "        train_step += 1\n",
    "    avg_loss = avg_loss / train_step\n",
    "    avg_train_acc = avg_train_acc / train_step\n",
    "    \n",
    "    for images, labels in test_ds:\n",
    "        acc = evaluate(model, images, labels)\n",
    "        avg_test_acc = avg_test_acc + acc\n",
    "        test_step += 1\n",
    "    avg_test_acc = avg_test_acc / test_step\n",
    "    \n",
    "    print(\"Epoch: {}\".format(e + 1),\n",
    "          \"loss: {:.8f}\".format(avg_loss),\n",
    "          \"train acc: {:.4f}\".format(avg_train_acc),\n",
    "          \"test acc: {:.4f}\".format(avg_test_acc))\n",
    "    \n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with Functional API\n",
    "We can find out that it works in Sequential API. Now let's implement it with another approach, the Functional APIs. Whole process will be same, except building model section.\n",
    "\n",
    "There is some limitation while building model with Sequential API. As you can see from `create_model`, whole layers are connected in one pipeline. But what if we want to use multi-input, or multi-output? And in Sequaltial API, we cannot mannually build the layer block. For instance, [ResNet](https://arxiv.org/abs/1512.03385) uses specific block named **residual block** that contained **skip connection**. But we cannot implement manual block in sequential API. Or we cannot build shared layers, so same layer is called several times.\n",
    "\n",
    "Actually, building process is almost similar with that of Sequential API. All we need to do is to define input, output, and connect each layers like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_functional():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', \n",
    "                                   activation=tf.keras.activations.relu)(inputs)\n",
    "    pool1 = tf.keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME',\n",
    "                                   activation=tf.keras.activations.relu)(pool1)\n",
    "    pool2 = tf.keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
    "    conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                   activation=tf.keras.activations.relu)(pool2)\n",
    "    pool3 = tf.keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
    "    pool3_flat = tf.keras.layers.Flatten()(pool3)\n",
    "    dense4 = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu)(pool3_flat)\n",
    "    drop4 = tf.keras.layers.Dropout(rate=0.4)(dense4)\n",
    "    logits = tf.keras.layers.Dense(units=10)(drop4)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model_functional()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the summary of model, the total parameter is the same as previous one. Interest thing is that the default name is defined as \"functional_x\". From these, we can found out that our new model is implemented with functional API.\n",
    "\n",
    "One more example, in Residual block, we can implement skip connection like this,\n",
    "\n",
    "![skip connection](image/skip_connection.png)\n",
    "\n",
    "```python\n",
    "inputs = tf.keras.Input(shape=(28, 28, 256))\n",
    "conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(1, 1), padding='SAME', activation=tf.keras.activations.relu)(inputs)\n",
    "conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=tf.keras.activations.relu)(conv1)\n",
    "conv3 = tf.keras.layers.Conv2D(filters=256, kernel_size=(1, 1), padding='SAME')(conv2)\n",
    "# skip connection\n",
    "add3 = tf.keras.layers.add([conv3, inputs])\n",
    "relu3 = tf.keras.activations.relu(add3)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=relu3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with Model Subclassing\n",
    "The other way to build model is Subclassing. Technically, it is defined model with python Class. Model Subclassing is the approach to build a fully-customizable model by subclassing `tf.keras.Model`. So we can define the inital implementation like layer, node parameter on `__init__` method, and forward pass on `call` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME',\n",
    "                                            activation=tf.keras.activations.relu)\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D(padding='SAME')\n",
    "        self.pool3_flat = tf.keras.layers.Flatten()\n",
    "        self.dense4 = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu)\n",
    "        self.drop4 = tf.keras.layers.Dropout(rate=0.4)\n",
    "        self.dense5 = tf.keras.layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        net = self.conv2(net)\n",
    "        net = self.pool2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.pool3(net)\n",
    "        net = self.pool3_flat(net)\n",
    "        net = self.dense4(net)\n",
    "        net = self.drop4(net)\n",
    "        net = self.dense5(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we just instantiate the `CNNModel` class, so the connection is not connected when instantiates. If we want to find the summary of this network, we need to build it or fit it with some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           multiple                  320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           multiple                  73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  524544    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 619,786\n",
      "Trainable params: 619,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(1, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with Model Ensemble\n",
    "The last method to build model is Ensemble method. Actually, the keyword **ensemble**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
